---
title: "Chapter 4 - Geocentric Model"
format: html
---

R code 4.1
```{r}
library(rethinking)
pos <- replicate(1e4, sum(runif(16, -1, 1)))
dens(pos)
```

R code 4.3
```{r}
growth <- replicate(1e4, prod(1 + runif(12, 0, 0.1)))
dens(growth, norm.comp = TRUE)
```

R Code 4.4
```{r}
big <- replicate(1e4, prod(1 + runif(12, 0, 0.5)))
dens(big, norm.comp = TRUE)
```

R code 4.5
```{r}
log.big <- replicate(1e4, log(prod(1 + runif(12, 0, 0.5))))
dens(log.big, norm.comp = TRUE)
```

R code 4.7 - R code 4.11
```{r}
library(rethinking)
data("Howell1")
d <- Howell1
precis(d)

d2 <- d[d$age >= 18, ]
dens(d2$height)
```

R code 4.12 - R code 4.13
```{r}
curve(dnorm(x, 178, 20), from = 100, to = 250)
curve(dunif(x, 0, 50), from = 10, to = 60)
```

Prior Predictive Simulation
R code 4.14
```{r}
sample_mu <- rnorm(1e4, 178, 20)
sample_sigma <- runif(1e4, 0, 50)
prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
```

R code 4.15
```{r}
sample_mu <- rnorm(1e4, 178, 100)
prior_h <- rnorm(1e4, sample_mu, sample_sigma)
dens(prior_h)
```

R codee 4.16
```{r}
mu.list <- seq(from = 150, to = 160, length.out = 100)
sigma.list <- seq(from = 7, to = 9, length.out = 100)
post <- expand.grid(mu = mu.list, sigma = sigma.list)
post$LL <- sapply(1:nrow(post), function(i) sum(dnorm(d2$height, post$mu[i], post$sigma[i], log = TRUE)))
post$prod <- post$LL + dnorm(post$mu, 178, 20, TRUE) + dunif(post$sigma, 0, 50, TRUE)
post$prob <- exp(post$prod - max(post$prod))
contour_xyz(post$mu, post$sigma, post$prob)
image_xyz(post$mu, post$sigma, post$prob)
```

R code 4.19
```{r}
sample.rows <- sample(1:nrow(post), size = 1e4, replace = TRUE, prob = post$prob)
sample.mu <- post$mu[sample.rows]
sample.sigma <- post$sigma[sample.rows]
plot(sample.mu, sample.sigma, cex = 0.5, pch = 16, col = col.alpha(rangi2, 0.1))
```

R code 4.21 - 4.22
```{r}
dens(sample.mu, adj = 0.1)
dens(sample.sigma, adj = 0.1)
PI(sample.mu)
PI(sample.sigma)
```

R code 4.23 - 4.24
```{r}
d3 <- sample(d2$height, size = 20)

mu.list <- seq(from = 150, to = 170, length.out = 200)
sigma.list <- seq(from = 4, to = 20, length.out = 200)
post2 <- expand.grid(mu = mu.list, sigma = sigma.list)
post2$LL <- sapply(1:nrow(post2), function(i) sum(dnorm(d3, mean = post2$mu[i], sd = post2$sigma[i], log = TRUE)))
post2$prod <- post2$LL + dnorm(post2$mu, 178, 20, TRUE) + dunif(post2$sigma, 0, 50, TRUE)
post2$prob <- exp(post2$prod - max(post2$prod))
sample2.rows <- sample(1:nrow(post2), size = 1e4, replace = TRUE, prob = post2$prob)
sample2.mu <- post2$mu[sample2.rows]
sample2.sigma <- post2$sigma[sample2.rows]
plot(sample2.mu, sample2.sigma, cex = 0.5, col = col.alpha(rangi2, 0.1), xlab = "mu", ylab = "sigma", pch = 16)
dens(sample2.sigma, norm.comp = TRUE)
```

Quadratic Approximation
R code 4.26
```{r}
rm(list = ls())

library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[d$age >= 18, ]

flist <- alist(
  height ~ dnorm(mu, sigma),
  mu ~ dnorm(178, 20),
  sigma ~ dunif(0, 50)
)

m4.1 <- quap(flist, data = d2)
precis(m4.1)
```

R code 4.31
```{r}
m4.2 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu ~ dnorm(178, 0.1),
    sigma ~ dunif(0, 50)
  ), data = d2
)
precis(m4.2)
```

R code 4.32
```{r}

# get diagonal value from variance-covariance matrix
diag(vcov(m4.1))

# get correlation of parameters from covariance matrix
cov2cor(vcov(m4.1))
```

R code 4.34
```{r}
library(rethinking)

# extracting samples from posterior distribution m4.1
post <- extract.samples(m4.1, n = 1e4)
precis(post)
```

### Linear Prediction
R code 4.37
```{r}
library(rethinking)
library(ggplot2)

data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18, ]

plot(d2$height ~ d2$weight)
ggplot(d2, aes(y = height, x = weight)) + geom_point() + theme_minimal()
```

This code is used to plot multiple lines that corresponds to different value of alpha and beta
R code 4.38
```{r}
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18, ]

set.seed(2971)
N <- 100 # 100 lines
a <- rnorm(N, 178, 20)

# we can try to use two distribution of b:
# 1. where b is distributed normally
# 2. where log(b) is distributed normally
# b <- rnorm(N, 0, 10)
b <- rlnorm(N, 0, 1)

plot(NULL, xlim = range(d2$weight), ylim = c(-100, 400), xlab = "weight", ylab = "height")
abline(h = 0, lty = 2)
abline(h = 272, lty = 1, lwd = 0.5)
mtext("b ~ dnorm(0, 10)")
xbar <- mean(d2$weight)
for(i in 1:N) curve(a[i] + b[i]*(x - xbar), from = min(d2$weight), to = max(d2$weight), add = TRUE, col = col.alpha("black", 0.2))
```

Create posterior approximation based on actual data
R code 4.42
```{r}

# load data
library(rethinking)
data("Howell1")
d <- Howell1
d2 <- d[d$age >= 18, ]

# define average weight xbar
xbar <- mean(d2$weight)

# fit model
m4.3 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b*(weight - xbar),
    a ~ dnorm(178, 20),
    b ~ dlnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = d2
)
```

Inspect the output of the model in tabular form
R code 4.4
```{r}
# read the marginal posterior distribution
precis(m4.3)

# inspect the variance-covariance matrix for the parameter
round(vcov(m4.3), 3)
```

Plot the posterior inference against the data
R code 4.46
```{r}

# code below plots the raw data, computes the posterior mean for a and b, then draws the implied line
plot(height ~ weight, data = d2, col = rangi2)
post <- extract.samples(m4.3)
a_map <- mean(post$a)
b_map <- mean(post$b)
curve(a_map + b_map*(x - xbar), add = TRUE)
```

Adding uncertainty around the mean.
We will use limited amount of data to recreate the model to emphasize the uncertainty around the mean (which is bigger with limited amount of data)
R code 4.48 - 4.49
```{r}
library(rethinking)

# Create the model
N <- 10
dN <- d2[1:N, ]
mN <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b * (weight - mean(weight)),
    a ~ dnorm(178, 20),
    b ~ dlnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = dN
)

# extract 20 samples from the posterior
post <- extract.samples(mN, n = 20)

# display raw data and sample size
plot(dN$weight, dN$height, xlim = range(d2$weight), ylim = range(d2$height), col = rangi2, xlab = "weight", ylab = "height")
mtext(concat("N = ", N))

# plot the lines, with transparency
for(i in 1:20) curve(post$a[i] + post$b[i] * (x - mean(dN$weight)), col = col.alpha("black", 0.3), add = TRUE)
```

Instead of plotting multiple regression lines with different values of parameters we will create a interval or contour around the average regression line
R code 4.50
```{r}
post <- extract.samples(m4.3)
mu_at_50 <- post$a + post$b * (50 - xbar)

dens(mu_at_50, col = rangi2, lwd = 2, xlab = "mu | weight = 50")
PI(mu_at_50, prob = 0.89)
```

Plot distribution of mu for each unique weight value on the horizontal axis
```{r}
# define sequence of weights to compute predictions for
# these values will be on the horizontal axis
weight.seq <- seq(from = 25, to = 70, by = 1)

# use link to compute mu
# for each sample from posterior
# and for each weight in weight.seq
mu <- link(m4.3, data = data.frame(weight = weight.seq))
str(mu)

# use type="n" to hide raw data
plot(height ~ weight, d2, type = "n")

# loop over samples and plot each mu value
for(i in 1:100)
  points(weight.seq, mu[i,], pch = 16, col = col.alpha(rangi2, 0.1))
```

Summarize the distribution for each weight value
```{r}
# summarize the distribution of mu
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI, prob = 0.89)
mu.HPDI <- apply(mu, 2, HPDI)

# plot raw data
# fading out points to make line and interval more visible
plot(height ~ weight, data = d2, col = col.alpha(rangi2, 0.5))

# plot the MAP line, aka the mean mu for each weight
lines(weight.seq, mu.mean)

# plot a shaded region for 89% PI
shade(mu.PI, weight.seq)
```

Prediction intervals
We need to incorporate the uncertainty for the prediction because observed data should be distributed around mu with standard devivation sigma
```{r}
sim.height <- sim(m4.3, data = list(weight = weight.seq))
str(sim.height)
height.PI <- apply(sim.height, 2, PI, prob = 0.89)

# plot raw data
plot(height ~ weight, d2, col = col.alpha(rangi2, 0.5))

# draw MAP line
lines(weight.seq, mu.mean)

# draw HPDI region for the line
shade(mu.HPDI, weight.seq)

# draw PI region for simulated heights
shade(height.PI, weight.seq)
```

### Curves from lines

Polynomial regression
```{r}
rm(list = ls())
library(rethinking)
data("Howell1")
d <- Howell1
d$weight_s <- (d$weight - mean(d$weight)) / sd(d$weight)
d$weight_s2 <- d$weight_s^2
m4.5 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b1*weight_s + b2*weight_s2,
    a ~ dnorm(178, 20),
    b1 ~ dlnorm(0, 1),
    b2 ~ dnorm(0, 1),
    sigma ~ dunif(0, 50)
  ),
  data = d
)

precis(m4.5)
```

Plot the parameters
```{r}
weight.seq <- seq(from = -2.2, to = 2, length.out = 30)
pred_dat <- list(weight_s = weight.seq, weight_s2 = weight.seq^2)
mu <- link(m4.5, data = pred_dat)
mu.mean <- apply(mu, 2, mean)
mu.PI <- apply(mu, 2, PI, prob = 0.89)
sim.height <- sim(m4.5, data = pred_dat)
height.PI <- apply(sim.height, 2, PI, prob = 0.89)

plot(height ~ weight_s, d, col = col.alpha(rangi2, 0.5))
lines(weight.seq, mu.mean)
shade(mu.PI, weight.seq)
shade(height.PI, weight.seq)
```

Cubic polynomial regression
```{r}
d$weight_s3 <- d$weight_s^3
m4.6 <- quap(
  alist(
    height ~ dnorm(mu, sigma),
    mu <- a + b1 * weight_s + b2 * weight_s2 + b3 * weight_s3,
    a ~ dnorm(178, 20),
    b ~ dlnorm(0, 1),
    b1 ~ dnorm(0, 10),
    b2 ~ dnorm(0, 10),
    b3 ~ dnorm(0, 10),
    sigma ~ dunif(0, 50)
  ), data = d
)

plot(height ~ weight_s, d, col = col.alpha(rangi2, 0.5), xaxt = "n")

at <- c(-2, -1, 0, 1, 2)
labels <- at * sd(d$weight) + mean(d$weight)
axis(side = 1, at = at, labels = round(labels, 1))
```

Line curve using b-splines
```{r}
rm(list = ls())
library(rethinking)
data("cherry_blossoms")
d <- cherry_blossoms
precis(d)

d2 <- d[complete.cases(d$doy), ] # complete cases on doy
num_knots <- 15
knot_list <- quantile(d2$year, probs = seq(0, 1, length.out = num_knots))
```

Create the splines
```{r}
library(splines)
B <- bs(d2$year, knots = knot_list[-c(1, num_knots)], degree = 3, intercept = TRUE)

plot(NULL, xlim = range(d2$year), ylim = c(0, 1), xlab = "year", ylab = "basis")
for(i in 1:ncol(B)) lines(d2$year, B[, i])

m4.7 <- quap(
  alist(
    D ~ dnorm(mu, sigma),
    mu <- a + B %*% w,
    a ~ dnorm(100, 10),
    w ~ dnorm(0, 10),
    sigma ~ dexp(1)
  ),
  data = list(D = d2$doy, B = B),
  start = list(w = rep(0, ncol(B)))
)

post <- extract.samples(m4.7)
w <- apply(post$w, 2, mean)
plot(NULL, xlim = range(d2$year), ylim = c(-6, 6), xlab = "year", ylab = "basis * weight")
for(i in 1:ncol(B)) lines(d2$year, w[i] * B[,i])

mu <- link(m4.7)
mu_PI <- apply(mu, 2, PI, 0.97)
plot(d2$year, d2$doy, col = col.alpha(rangi2, 0.3), pch = 16)
shade(mu_PI, d2$year, col = col.alpha("black"), 0.5)
```

