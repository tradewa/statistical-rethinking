---
title: "Chapter 3 BRMS"
format: html
---

# 3 Sampling the Imaginary

```{r}
# clean workspace
rm(list = ls())

# call required library
library(ggdist)
library(tidyverse)
library(patchwork)
library(tidybayes)
```

```{r}
tibble(pr_positive_vampire = .95,
       pr_positive_mortal = .01,
       pr_vampire = .001) %>%
  mutate(pr_positive = pr_positive_vampire * pr_vampire + pr_positive_mortal * (1 - pr_vampire)) %>%
  mutate(pr_vampire_positive = pr_positive_vampire * pr_vampire / pr_positive) %>%
  glimpse()
```

```{r}
tibble(pr_vampire = 100 / 100000,
       pr_positive_vampire = 95 / 100,
       pr_positive_mortal = 999 / 99900) %>%
  mutate(pr_positive = 95 + 999) %>%
  mutate(pr_vampire_positive = pr_positive_vampire * 100 / pr_positive) |>
  glimpse()
```

## 3.1 Sampling from a grid-approximate posterior
```{r}
# how many grid points would you like?
n <- 1000
n_success <- 6
n_trials <- 9

(
  d <-
    tibble(p_grid = seq(from = 0, to = 1, length.out = n),
           # note we're stil using a flat uniform prior
           prior = 1) |>
    mutate(likelihood = dbinom(n_success, size = n_trials, prob = p_grid)) |>
    mutate(posterior = likelihood * prior / sum(likelihood * prior))
)
```

Get samples from posterior
```{r}
# how many samples would you like?
n_samples <- 1e4

# make it reproducible
set.seed(3)

samples <-
  d |>
  slice_sample(n = n_samples, weight_by = posterior, replace = T)

glimpse(samples)
```

Plot samples
```{r}
samples |>
  mutate(sample_number = 1:n()) |>
  
  ggplot(aes(x = sample_number, y = p_grid)) +
  geom_point(alpha = 1/10) +
  scale_y_continuous("proportion of water (p)", limits = c(0, 1)) +
  xlab("sample number")
```

Density of samples
```{r}
samples |>
  ggplot(aes(x = p_grid)) +
  geom_density(fill = "black") +
  scale_x_continuous("proportion of water (p)", limits = c(0, 1))
```

Create density with 1mn sample to see smoother density
```{r}
set.seed(3)

d |>
  slice_sample(n = 1e6, weight_by = posterior, replace = T) |>
  
  ggplot(aes(x = p_grid)) +
  geom_density(fill = "black") +
  scale_x_continuous("proportion of water (p)", limits = c(0, 1))
```

## 3.2 Sampling to summarize
### 3.2.1 Intervals of defined boundaries
```{r}
# Get proportion of water less than some value of p_grid
d |>
  filter(p_grid < .5) |>
  summarise(sum = sum(posterior))

# Create frequency based on filtering by samples
samples |>
  filter(p_grid < .5) |>
  summarise(sum = n() / n_samples)

# A more explicit approach for the same computation
samples |>
  filter(p_grid < .5) |>
  mutate(probability = n / sum(n))

samples |>
  summarise(sum = mean(p_grid < .5))

# Determine posterior probability between 0.5 and 0.75
samples |>
  filter(p_grid > .5 & p_grid < .75) |>
  summarise(sum = n() / n_samples)

# Multiply by 100 to get percent
samples |>
  filter(p_grid > .5 & p_grid < .75) |>
  summarise(sum = n() / n_samples,
            percent = n() / n_samples * 100)
```
### 3.2.2 Intervals of defined mass
```{r}
# upper left panel
p1 <-
  d |>
  ggplot(aes(x = p_grid, y = posterior)) +
  geom_line() +
  geom_area(data = d |> filter(p_grid < .5)) +
  labs(x = "proportion of water (p)",
       y = "density")

# upper right panel
p2 <-
  d |>
  ggplot(aes(x = p_grid, y = posterior)) +
  geom_line() +
  # note this next line is the only difference in code from the last plot
  geom_area(data = d |> filter(p_grid < .75 & p_grid > .5)) +
  labs(x = "proportion of water (p)",
       y = "density")

# combine
p1 + p2
```

Lower two panels
```{r}
(q_80 <- quantile(samples$p_grid, prob = .8))

samples |>
  pull(p_grid) |>
  quantile(prob = .8)

samples |>
  summarise('80th percentile' = quantile(p_grid, p = .8))

(q_10_and_90 <- quantile(samples$p_grid, prob = c(.1, .9)))
```

```{r}
# lower left panel
p1 <-
  d |>
  ggplot(aes(x = p_grid, y = posterior)) +
  geom_line() +
  geom_area(data = d |> filter(p_grid < q_80)) +
  annotate(geom = "text",
           x = .25, y = .0025,
           label = "lower 80%") +
  labs(x = "proportion of water (p)",
       y = "density")

# lower right panel
p2 <-
  d |>
  ggplot(aes(x = p_grid, y = posterior)) +
  geom_line() +
  geom_area(data = d |> filter(p_grid > q_10_and_90[1] & p_grid < q_10_and_90[2])) +
  annotate(geom = "text",
           x = .25, y = .0025,
           label = "middle 80%") +
  labs(x = "proportion of water (p)",
       y = "density")

# combine
p1 + p2
```

```{r}
# here we update the 'dbinom()' parameters
n_success <- 3
n_trials <- 3

# update 'd'
d <-
  d |>
  mutate(likelihood = dbinom(n_success, size = n_trials, prob = p_grid)) |>
  mutate(posterior = (likelihood * prior) / sum(likelihood * prior))

# make the next part reproducible
set.seed(3)

# here's our new samples tibble
(
  samples <-
    d |>
    slice_sample(n = n_samples, weight_by = posterior, replace = T)
)
```

```{r}
quantile(samples$p_grid, prob = c(.25, .75))

rethinking::PI(samples$p_grid, prob = .5)
```
Introduce tidybayes package for summarizing Bayesian models
```{r}
median_qi(samples$p_grid, .width = .5)
median_qi(samples$p_grid, .width = c(.5, .8, .99))

rethinking::HPDI(samples$p_grid, prob = .5)

mode_hdi(samples$p_grid, .width = .5)

qi(samples$p_grid, .width = .5)


```

```{r}
# lower left panel
p1 <-
  d |>
  ggplot(aes(x = p_grid, y = posterior)) +
  # check out our sweet 'qi()' indexing
  geom_area(data = d |>
              filter(p_grid > qi(samples$p_grid, .width = .5)[1] & p_grid < qi(samples$p_grid, .width = .5)[2]),
            fill = "grey75") +
  geom_line() +
  labs(subtitle = "50th Percentile Interval",
       x = "proportion of water (p)",
       y = "density")

# lower right panel
p2 <-
  d |>
  ggplot(aes(x = p_grid, y = posterior)) +
  geom_area(data = d |>
              filter(p_grid > hdi(samples$p_grid, .width = .5)[1] &
                       p_grid < hdi(samples$p_grid, .width = .5)[2]),
            fill = "grey75") +
  geom_line() +
  labs(subtitle = "50% HPDI",
       x = "proportion of water (p)",
       y = "density")

# combine
p1 | p2
```
Update the simulation for six waters in nine tosses
```{r}
# "six waters in nine tosses"
n_success <- 6
n_trials <- 9

new_d <-
  d |> 
  mutate(likelihood = dbinom(n_success, size = n_trials, prob = p_grid)) |> 
  mutate(posterior = (likelihood * prior) / sum(posterior))

set.seed(3)

new_samples <-
  new_d |> 
  slice_sample(n = n_samples, weight_by = posterior, replace = T)
```

Here are the intervals by .width and type of .interval
```{r}
bind_rows(mean_hdi(new_samples$p_grid, .width = c(.8, .95)),
          mean_qi(new_samples$p_grid, .width = c(.8, .95))) |> 
  select(.width, .interval, ymin:ymax) |> 
  arrange(.width) |> 
  mutate_if(is.double, round, digits = 2)
```

posterior plot
```{r}
new_d |> 
  ggplot(aes(x = p_grid)) +
  geom_line(aes(y = posterior)) +
  labs(subtitle = "Six waters in nine tosses made\nfor a more symmetrical posterior",
       x = "proportion of water (p)",
       y = "density")
```

### 3.2.3 Point estimates.
```{r}
d |> 
  arrange(desc(posterior))

d |> 
  arrange(desc(posterior)) |> 
  slice(1)

samples |> mode_hdi(p_grid)

samples |> mode_qi(p_grid)

Mode(samples$p_grid)

samples |> 
  summarize(mean = mean(p_grid),
            median = median(p_grid))
```

We can inspect the three types of point estimate
```{r}
(
  point_estimates <-
  bind_rows(samples |> mean_qi(p_grid),
            samples |> median_qi(p_grid),
            samples |> mode_qi(p_grid),) |> 
  select(p_grid, .point) |> 
  # these last two columns will help us annotate
  mutate(x = p_grid + c(-.03, .03, -.03),
         y = c(.0005, .0012, .002))
)
```

```{r}
d |> 
  ggplot(aes(x = p_grid)) +
  geom_area(aes(y = posterior),
            fill = "grey75") +
  geom_vline(xintercept = point_estimates$p_grid) +
  geom_text(data = point_estimates,
            aes(x = x, y = y, label = .point),
            angle = 90) +
  labs(x = "proportion of water (p)",
       y = "density") +
  theme(panel.grid = element_blank())
```
Let p be the proportion of the Earth covered by water and d be our guess. If McElreath pays us $100 if we guess exactly right but subtracts money from the prize proportional to how far off we are, then our loss i sprportional to d - p. If we decide d = .5, we can compute our expected loss
```{r}
d |> 
  summarize('expected loss' = sum(posterior * abs(0.5 - p_grid)))
```

```{r}
make_loss <- function(our_d){
  d |> 
    mutate(loss = posterior * abs(our_d - p_grid)) |> 
    summarize(weighted_average_loss = sum(loss))
}

(
  l <-
    d |> 
    select(p_grid) |> 
    rename(decision = p_grid) |> 
    mutate(weighted_average_loss = purrr::map(decision, make_loss)) |> 
    unnest(weighted_average_loss)
)
```

```{r}
min_loss <-
  l |> 
  filter(weighted_average_loss == min(weighted_average_loss)) |> 
  as.numeric()

l |> 
  ggplot(aes(x = decision, y = weighted_average_loss)) +
  geom_area(fill = "grey75") +
  geom_vline(xintercept = min_loss[1], color = "white", linetype = 3) +
  geom_hline(yintercept = min_loss[2], color = "white", linetype = 3) +
  ylab("expected proportional loss") +
  theme(panel.grid = element_blank())
```

Let's investigate quadratic loss
```{r}
# amend our loss function
make_loss <- function(our_d){
  d |> 
    mutate(loss = posterior * (our_d - p_grid)^2) |> 
    summarize(weighted_average_loss = sum(loss))
}

# remake our 'l' data
l <-
  d |> 
  select(p_grid) |> 
  rename(decision = p_grid) |> 
  mutate(weighted_average_loss = purrr::map(decision, make_loss)) |> 
  unnest(weighted_average_loss)

# update to the new minimum loss coordinates
min_loss <-
  l |> 
  filter(weighted_average_loss == min(weighted_average_loss)) |> 
  as.numeric()

# update the plot
l |> 
  ggplot(aes(x = decision, y = weighted_average_loss)) +
  geom_area(fill = "grey75") +
  geom_vline(xintercept = min_loss[1], color = "white", linetype = 3) +
  geom_hline(yintercept = min_loss[2], color = "white", linetype = 3) +
  ylab("expected proportional loss") +
  theme(panel.grid = element_blank())
```

## 3.3 Sampling to simulate prediction
### 3.3.1 Dummy data
```{r}
n_draws <- 1e5

set.seed(3)

d <- tibble(draws = rbinom(n_draws, size = 2, prob = .7))

d |> 
  count(draws) |> 
  mutate(proportion = n / nrow(d))
```

```{r}
d <- tibble(draws = rbinom(n_draws, size = 9, prob = .7))

# the histogram
d |> 
  ggplot(aes(x = draws)) +
  geom_histogram(binwidth = 1, center = 0,
                 color = "grey92", linewidth = 1/10) +
  scale_x_continuous("dummy water count", breaks = 0:4 * 2) +
  ylab("frequency") +
  coord_cartesian(xlim = c(0, 9)) +
  theme(panel.grid = element_blank())
```
McElreath suggested we play around with different values of size and prob. With th next block of code, we'll simulate nine conditions
```{r}
n_draws <- 1e5

simulate_binom <- function(n, probability){
  set.seed(3)
  rbinom(n_draws, size = n, prob = probability)
}

d <-
  crossing(n = c(3, 6, 9),
           probability = c(.3, .6, .9)) |> 
  mutate(draws = map2(n, probability, simulate_binom)) |> 
  ungroup() |> 
  mutate(n = str_c("n = ", n),
         probability = str_c("p = ", probability)) |> 
  unnest(draws)

head(d)
```

Plot the simulation results
```{r}
d |> 
  ggplot(aes(x = draws)) +
  geom_histogram(binwidth = 1, center = 0,
                 color = "grey92", linewidth = 1/10) +
  scale_x_continuous("dummy water count", breaks = 0:4 * 2) +
  ylab("frequency") +
  coord_cartesian(xlim = c(0, 9)) +
  theme(panel.grid = element_blank()) +
  facet_grid(n ~ probability)
```

### 3.3.2 Model checking
#### 3.3.2.2 Is the model adequate?
```{r}
# how many grid points would you like?
n <- 1001
n_success <- 6
n_trials <- 9

(
  d <-
    tibble(p_grid = seq(from = 0, to = 1, length.out = n),
           prior = 1) |> 
    mutate(likelihood = dbinom(n_success, size = n_trials, prob = p_grid)) |> 
    mutate(posterior = (likelihood * prior) / sum(likelihood * prior))
)
```

Make the figure
```{r}
d |> 
  ggplot(aes(x = p_grid, y = posterior)) +
  geom_area(color = "grey67", fill = "grey67") +
  geom_segment(data = d |> 
                 filter(p_grid %in% c(seq(from = .1, to = .9, by = .1), 3 / 10)),
               aes(xend = p_grid, yend = 0, linewidth = posterior),
               color = "grey33", show.legend = F) +
  geom_point(data = d |> 
               filter(p_grid %in% c(seq(from = .1, to = .9, by = .1), 3 / 10))) +
  annotate(geom = "text",
           x = .08, y = .0025,
           label = "Posterior probability") +
  scale_linewidth_continuous(range = c(0, 1)) +
  scale_x_continuous("probability of water", breaks = 0:10 / 10) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

```{r}
n_draws <- 1e5

simulate_binom <- function(probability){
  set.seed(3)
  rbinom(n_draws, size = 9, prob = probability)
}

d_small <-
  tibble(probability = seq(from = .1, to = .9, by = .1)) |> 
  mutate(draws = purrr::map(probability, simulate_binom)) |> 
  unnest(draws) |> 
  mutate(label = str_c("p = ", probability))

head(d_small)
```

```{r}
d_small |> 
  ggplot(aes(x = draws)) +
  geom_histogram(binwidth = 1, center = 0,
                 color = "grey92", linewidth = 1/10) +
  scale_x_continuous(NULL, breaks = 0:3 * 3) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "Sampling distributions") +
  coord_cartesian(xlim = c(0, 9)) +
  theme(panel.grid = element_blank()) +
  facet_wrap(~ label, ncol = 9)
```

```{r}
n_samples <- 1e4

set.seed(3)

samples <-
  d |> 
  slice_sample(n = n_samples, weight_by = posterior, replace = T) |> 
  mutate(w = purrr::map_dbl(p_grid, rbinom, n = 1, size = 9))

glimpse(samples)
```

```{r}
samples |> 
  ggplot(aes(x = w)) +
  geom_histogram(binwidth = 1, center = 0,
                 color = "grey92", linewidth = 1/10) +
  scale_x_continuous("number of water samples", breaks = 0:3 * 3) +
  scale_y_continuous(NULL, breaks = NULL) +
  ggtitle("Posterior predictive distribution") +
  coord_cartesian(xlim = c(0, 9),
                  ylim = c(0, 3000)) +
  theme(panel.grid = element_blank())
```

Try again with unaggregated samples
```{r}
set.seed(3)

samples <-
  samples |> 
  mutate(iter = 1:n(),
         draws = purrr::map(p_grid, rbinom, n = 9, size = 1)) |> 
  unnest(draws)

glimpse(samples)

tosses <- c("w", "l", "w", "w", "w", "l", "w", "l", "w")

rle(tosses)

rle(tosses)$lengths |> max()
```

```{r}
samples |> 
  group_by(iter) |> 
  summarize(longest_run_length = rle(draws)$lengths |> max()) |> 
  
  ggplot(aes(x = longest_run_length)) +
  geom_histogram(aes(fill = longest_run_length == 3),
                 binwidth = 1, center = 0,
                 color = "grey92", linewidth = 1/10) +
  scale_fill_viridis_d(option = "D", end = .9) +
  scale_x_continuous("longest run length", breaks = 0:3 * 3) +
  ylab("frequency") +
  coord_cartesian(xlim = c(0, 9)) +
  theme(legend.position = "none",
        panel.grid = element_blank())
```

```{r}
rle(tosses)

rle(tosses)$lengths |> length()
```

```{r}
samples |> 
  group_by(iter) |> 
  summarize(longest_run_length = rle(draws)$lengths |> length()) |> 
  
  ggplot(aes(x = longest_run_length)) +
  geom_histogram(aes(fill = longest_run_length == 7),
                 binwidth = 1, center = 0,
                 color = "grey92", linewidth = 1/10) +
  scale_fill_viridis_d(option = "D", end = .9) +
  scale_x_continuous("longest run length", breaks = 0:3 * 3) +
  ylab("frequency") +
  coord_cartesian(xlim = c(0, 9)) +
  theme(legend.position = "none",
        panel.grid = element_blank())
  
```

## 3.4 Let's practice with brms
```{r}
library(brms)
```

```{r}
b3.1 <-
  brm(data = list(w = 6),
      family = binomial(link = "identity"),
      w | trials(9) ~ 0 + Intercept,
      # this is a flat prior
      prior(beta(1, 1), class = b, lb = 0, ub = 1),
      iter = 5000, warmup = 1000,
      seed = 3,
      file = "fits/b03.01")
```

Posterior summary for b_Intercept
```{r}
posterior_summary(b3.1)["b_Intercept", ] |> 
  round(digits = 2)
```

Much like the way we used the samples() function to simulate probability values, above, we can do so with the brms::fitted() function. But we will have to specify scale = "linear" in order to return results in the probability metric. By default, brms::fitted() will return summary information. Since we want actual simulation draws, we’ll specify summary = F.
```{r}
f <-
  fitted(b3.1,
         summary = F,
         scale = "linear") |> 
  data.frame() |> 
  set_names("p")

glimpse(f)
```

By default, we have a generically-named vector of 4,000 samples. We’ll explain the defaults in later chapters. For now, notice we can view these in a density.
```{r}
f |> 
  ggplot(aes(x = p)) +
  geom_density(fill = "grey50", color = "grey50") +
  annotate(geom = "text", x = .08, y = 2.5,
           label = "Posterior probability") +
  scale_x_continuous("probability of water",
                     breaks = c(0, .5, 1),
                     limits = 0:1) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid = element_blank())
```

Use above distribution probability to predict histrograms of w counts
```{r}
set.seed(3)

f <-
  f |>
  mutate(w = rbinom(n(), size = n_trials, prob = p))

f |> 
  ggplot(aes(x = w)) +
  geom_histogram(binwidth = 1, center = 0,
                 color = "grey92", linewidth = 1/10) +
  scale_x_continuous("number of water samples", breaks = 0:3 * 3) +
  scale_y_continuous(NULL, breaks = NULL, limits = c(0, 5000)) +
  ggtitle("Posterior predictive distribution") +
  coord_cartesian(xlim = c(0, 9)) +
  theme(panel.grid = element_blank())
```

```{r}
sessionInfo()
```

